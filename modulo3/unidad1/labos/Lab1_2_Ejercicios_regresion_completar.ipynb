{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab1_2_Ejercicios_regresion_completar.ipynb","provenance":[{"file_id":"1NSfimgFz-zoP6VGiXVzN8Dij3azcSfvT","timestamp":1633149191793},{"file_id":"1RAAo1r5GFxmk4bxddsns390exh5sBBMZ","timestamp":1633146308470}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"2THCK8_htCwa"},"source":["**Objetivo general**: a través de este laboratorio pretendemos establecer buenas prácticas en el proceso de análisis de datos y modelos predictivos."]},{"cell_type":"markdown","metadata":{"id":"biOGfrdntKaU"},"source":["**Objetivo particular**: implementar un esquema completo desde el análisis de los datos hasta la construcción del modelo de regresión que permita predecir costos de viviendas partiendo de diferentes atributos de las mismas.\n","\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"YaqiS-5SrYyD"},"source":["\n","**Parte 1**: Análisis y visualización de datos\n","  *   Tipos de variables.\n","  *   Identificación de valores faltantes.\n","  *   Identificación de valores atípicos (outliers).\n","  *   Correlación de variables.\n","\n","---\n","\n","**Parte 2**: Modelo\n","  * Ingeniería de características.\n","  * Modelo predictivo.\n","    * Entrenamiento, validación y test."]},{"cell_type":"markdown","metadata":{"id":"LXLi9pd8t_24"},"source":["### Dataset\n","La base de datos contiene información sobre atributos utilizados para tasar propiedades residenciales en la ciudad de Ames (Iowa).\n","\n","- **Período**: 2006 - 2010\n","- **Cantidad de variables**: 82\n","- **Fuente**: Oficina de Tasación de inmuebles de Ames (Iowa)\n","- **Información adicional**\n","   -  http://jse.amstat.org/v19n3/decock.pdf\n","   -  [codebook](https://drive.google.com/file/d/1pDkSyI8UHtLEFdjpAVNmsVqB8N6a5Pqv/view?usp=sharing)"]},{"cell_type":"markdown","metadata":{"id":"bMOv7ntrvoK7"},"source":["## Parte 2: Entrenar modelos de regresión"]},{"cell_type":"code","metadata":{"id":"K5eM4N3YzZK9"},"source":["import pandas as pd\n","import seaborn as sns\n","from matplotlib import pyplot as plt\n","\n","!pip install plotly==5.3.1                  \n","import plotly.express as px                 # Librería que permite realizar visualizaciones interactivas \n","                                            # Algunas funciones usadas se encuentran en versiones más actuales: desde la  4.12.0\n","                                            # Si tiene una versión anterior, instalar: !pip install plotly==5.3.1\n","# Consultar versión de plotly instalada\n","import plotly\n","print(plotly.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iLxAtUaezfCn"},"source":["# Leemos el dataset\n","path = 'https://drive.google.com/uc?export=download&id=1UVZnskEk-GZbTo4uW2usL7ze92XVDS8_'\n","df = pd.read_csv(path)\n","\n","# Información básica del dataset\n","#df.info()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_gM3eDry1S-Y"},"source":["*Notar que existen atributos en los que se pueden encontrar algunos (o muchos) **valores faltantes**. Dados por la diferencia entre la cantidad de entradas y la cantidad de valores ```non-null```*"]},{"cell_type":"code","metadata":{"id":"eIk4QekfAsqQ"},"source":["missings = df.isna().sum()\n","missings[missings > 0].sort_values()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0hlbM7SKDDCI"},"source":["# Porcentaje de valores faltantes\n","\n","missings = df.isna().sum()      # Chequeamos los valores nulos y los contamos.\n","missings[missings > 0].sort_values()  # Filtramos solo aquellos que tienen valores nulos\n","\n","missing_percentage = (missings[missings > 0] / len(df) *100).sort_values()\n","missing_percentage"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dmu678yfGsGa"},"source":["attributes_to_drop = missing_percentage[missing_percentage > 16.0].index.to_list()\n","print('Los atributes a eliminar:', attributes_to_drop)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iGai6N_lIWFu"},"source":["df.drop(attributes_to_drop, axis=1, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xe-8ZIjhKjue"},"source":["Similarmente, podemos optar por eliminar aquellas pocas filas que pierden atributos. EL siguiente código funciona para eliminar la fila donde falta el valor para ```Electrical``` pero puede adaptarse para eliminar otros también."]},{"cell_type":"code","metadata":{"id":"wM5Vs53tKk7b"},"source":["# Buscamos el (los) indices donde faltan pocos atributos.\n","attributes_least_missing = ['Electrical', 'TotalBsmtSF', 'GarageArea', 'GarageCars', 'BsmtFinSF1', 'BsmtUnfSF', 'BsmtHalfBath', 'BsmtFullBath']\n","\n","idx_to_drop = []\n","for attribute in attributes_least_missing:\n","  idx_to_drop.extend(df[df[attribute].isna()].index)\n","print('Eliminamos las filas:', idx_to_drop)\n","\n","# Usamos el índice para eliminarlo de la tabla\n","df.drop(idx_to_drop, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VqRJUsjnMTTt"},"source":["df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sbUDkCf9L1Gm"},"source":["# Eliminar alguna fila hace que quede  discontinuo el índice del dataframe (Index)\n","# pero se puede resetear:\n","df.reset_index(drop=True, inplace=True)\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lnYudfSXWwbD"},"source":["missings = missing_percentage[missing_percentage <= 16.0].index.to_list()\n","\n","for a in attributes_least_missing:\n","  missings.remove(a)\n","missings"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZhbkrdnxYbQ_"},"source":["Si observamos el mapa de correlación, podemos ver que GarageYrBlt tiene alta correlación con YearBlt. Por lo tanto podemos eliminar esta variable."]},{"cell_type":"markdown","metadata":{"id":"y9n86XkwMYj_"},"source":["Se pueden considerar distintas alternativas. En muchos casos suele ser factible reemplazar los valores faltantes con los valores más frecuentes (moda), media o mediana.\n","\n","Otra opción puede ser intentar inferir estos valores a través de algún modelo de clasificación (usarndo las otras variables para entrenar el modelo)\n","\n","Por simplicidad vamos a eliminar estas variables. Apoyamos esta decisión por algunas observaciones como: El número de entradas es considerablemente bajo comparado con los otros casos. Las variables que tienen el mismo prefijo tienen la misma cantidad de valores nulos (probablemente se deba a que esos faltantes son en las mismas entradas (chequear)).\n"]},{"cell_type":"code","metadata":{"id":"eKaGcGnlfd3_"},"source":["df.drop(missings, axis=1, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eJ77T9_NgZE9"},"source":["df.info()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"phAEEfJLgdD8"},"source":["Ahora tenemos un dataset limpio para pensar en el el modelo que queremos utilzar.\n","\n","Dado que vamos a usar un modelo de regresión tendremos que chequear que se cumplan ciertas condiciones.\n","\n","Además, tenemos que poder representar las variables categóricas de manera numérica para finalmente entrenar y usar nuestro modelo predictivo."]},{"cell_type":"markdown","metadata":{"id":"1lchropIEm97"},"source":["### Ingeniería de características"]},{"cell_type":"markdown","metadata":{"id":"qaKkCpuEEt74"},"source":["Por un lado tenemos las características ordinales (listas para usar)\n","\n","Por el otro, las variables categóricas (incluidas los códigos numéricos que no presentan orden). Todas estas necesitan una representación numérica adecuada."]},{"cell_type":"markdown","metadata":{"id":"FzPpllJFPO32"},"source":["Notar que tampoco necesitamos usar Order ni PID para nuestro entrenamiento"]},{"cell_type":"code","metadata":{"id":"wPIMv0LdFDls"},"source":["# Dividimos las features segun son ordinales o categoricas\n","# Usar el codeBook para asegurarnos la correcta división\n","\n","#Notar incluso que hay una variable de tipo Object pero en la descripción \n","# se indica que es ordinal (HeatingQC):\n","# Ex\tExcellent        -> 5\n","# Gd\tGood             -> 4\n","# TA\tAverage/Typical  -> 3\n","# Fa\tFair             -> 2\n","# Po\tPoo              -> 1\n","\n","df['HeatingQC'] = df['HeatingQC'].replace({'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa':2, 'Po': 1})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T-oy10Nrylqs"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0k3u5TD0KNO2"},"source":["categorical = ['MSSubClass',\n","                'MSZoning',\n","                'Street',\n","                'LotShape',\n","                'LandContour',\n","                'Utilities',\n","                'LotConfig',\n","                'LandSlope',\n","                'Neighborhood',\n","                'Condition1',\n","                'Condition2',\n","                'BldgType',\n","                'HouseStyle',\n","                'RoofStyle',\n","                'RoofMatl',\n","                'Exterior1st',\n","                'Exterior2nd',\n","                'ExterQual',\n","                'ExterCond',\n","                'Foundation',\n","                'Heating',\n","                'CentralAir',\n","                'Electrical',\n","                'KitchenQual',\n","                'Functional',\n","                'PavedDrive',\n","                'SaleType',\n","                'SaleCondition']\n","df[categorical]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VtRoNMGJy26Q"},"source":["#### Tratamiento de variables categóricas como vectores *one-hot*"]},{"cell_type":"markdown","metadata":{"id":"YOHG60cwzDAh"},"source":["Por ejemplo:"]},{"cell_type":"code","metadata":{"id":"mKlatNXqLvdP"},"source":["# Ejemplo de codificación tipo \"One-hot\"\n","# Nos permite resolver el problema de no tener orden entre los distintos valores categóricos.\n","pd.get_dummies(df['PavedDrive'], prefix='PavedDrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n5LGe8P9MZKU"},"source":["# Necesitamos este tipo de codificación para todas las variables categóricas\n","# Podemos directamente aplicar este tipo de codificación sobre el dataFrame completo\n","# e indicar cuáles son las columnas categóricas:\n","\n","df_encoded = pd.get_dummies(data=df, columns=categorical)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k-vfsQPEOhIG"},"source":["# Separamos la variable objetivo del resto (es decir, dividimos el dataset en \"X e Y\" )\n","sale_price = df_encoded[['SalePrice']]                   # Y\n","df_encoded.drop('SalePrice', axis=1, inplace= True)      # X\n","\n","# Prescindimos de Order y PID (si bien no es necesaria esta información, la guardo por las dudads)\n","order_pid = df_encoded[['Order', 'PID']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"XVJaL7gMztJ4"},"source":["df_encoded"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6Zh_N1A6Hw8n"},"source":["### Ejemplo 1 (completar)\n","\n","En este ejemplo vamos a construir un modelo de regresión lineal simple\n","y para ellos usaremos SOLO UNA variable (elijan aquella que crean más adecuada):\n","\n","* Crear un modelo de regresión lineal (usando scikit-learn).\n","* Usar como entrenamiento un solo atributo (tomar el que crean más adecuado).\n","* Para entrenar, dividir los datos en entrenamiento y evaluación.\n","(Como tenemos solo un atributo, podemos graficar facilmente)\n"]},{"cell_type":"code","metadata":{"id":"uUmNRrqoIQo4"},"source":["from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error\n","from sklearn import metrics # por si quieren usar otras métricas.\n","\n","### Elegir una feature\n","### Crear X (dado el dataframe y la feature elegida)\n","\n","X = # >> completar <<<\n","y = df['SalePrice']\n","\n","# Generar el split train/test usando la función train_test_split:\n","# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n","# >> completar <<\n","\n","# Instanciar la clase que provee la regresión lineal\n","# ajustar el modelo\n","# >> completar <<\n","\n","# Generar la predicción\n","y_pred = # >> completar <<\n","\n","# Usar alguna métrica como MSE u otra para imprimir el error\n","#print('MSE:', # >> completar << ...\n","\n","# Plotear los puntos de entrenamiento\n","# >> completar <<\n","\n","# Plotear los puntos de test\n","# >> completar <<\n","\n","# Plotear la recta de regresión\n","# >> completar <<\n","\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sZ-D-NgINVdJ"},"source":["\n","\n","#### Repetimos con más de una features"]},{"cell_type":"code","metadata":{"id":"xHuF-56hNUHl"},"source":["features = # >> completar <<\n","X = # >> completar <<\n","y = df['SalePrice']\n","\n","# Generar el split train/test usando la función train_test_split\n","# Instanciar el modelo y ajustar\n","# Calcular el error y mostrar el resultado.\n","# >> completar <<\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dAf-NEY2K-9V"},"source":["**Extra**: generar el mismo procedimiento pero iterando en cantidad de features que agregamos, guardar los errores y ver gráficamente (features y error).\n","\n","La idea es ver si a medida que agregamos features el error disminuye."]},{"cell_type":"markdown","metadata":{"id":"q1IEMwAFUD4I"},"source":["### Ejemplo 2 (completar)"]},{"cell_type":"markdown","metadata":{"id":"FVpFUiwFUHp7"},"source":["De manera similar al ejemplo visto en el teórico, validar modelos polinómicos de distintos grados y generar una visualización que permita comparar los errores en el conjunto de entrenamiento y evaluación.\n","\n","Recordar generar las particiones (splits) necesarias para entrenar, validar y evaluar."]},{"cell_type":"code","metadata":{"id":"e4QGdSBwK7Pl"},"source":["\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import PolynomialFeatures\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error\n","from sklearn import metrics\n","from sklearn.model_selection import train_test_split\n","\n","\n","\n","X = # completar\n","y = df['SalePrice']\n","\n","# Split train+val y test\n","# train_test_split(...) # completar\n","\n","train_errors = []\n","val_errors = []\n","\n","degrees = [1, 2, 3, 4, 5, 6, 7]\n","for M in degrees:\n","    ### train ###\n","    # Usar PolynomialFeatures y LinearRegression\n","    # para construir el modelo polinómico,\n","    # apoyarse en make_pipeline para crear y ajustar el modelo.\n","    \n","    # completar\n","    \n","    \n","    # Generar las predicciones\n","    y_train_pred = # completar\n","    y_val_pred = # completar\n","    \n","    ### Evaluar ###\n","    # Usar alguna métrica (mean_squared_error, por ejemplo)\n","    # para guardar los errores de train y de test.\n","    train_error = # copmletar\n","    val_error = # completar\n","    train_errors.append(train_error)\n","    val_errors.append(val_error)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5lQYYo1vLQAD"},"source":["# graficar\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uwJZuK2PvRO3"},"source":["# Una vez comparados los modelos\n","# entrenar con todo el conjunto de entrenamiento y evaluar.\n","M = # completar\n"],"execution_count":null,"outputs":[]}]}